function net = bsds_cae_init2()

%very like init1 but less feature maps on code layer
% imitate the keras CAE and the struct of encoder and decoder 
%  is symmetry. first upsampling then decoder
% Meta parameters
net.meta.inputSize = [192 128 3 1] ;

net.layers = {} ; % K i.e. num. of the filters = num of channels*number of
% filters , for the RGB images

net.layers{end+1} = struct('type', 'conv', ...
                           'weights', {xavier(5,5,3,96)}, ...
                           'stride', 1, ...
                           'pad', [2 2 2 2] ,...
                           'learningRate', [1 1], ...
                           'weightDecay', [1 0]) ;
                       
net.layers{end+1} = struct('type', 'relu') ;
net.layers{end+1} = struct('type', 'pool', ...
                           'method', 'max', ...
                           'pool', [2 2], ...
                           'stride', 2, ...
                           'pad', 0) ;

                      
net.layers{end+1} = struct('type', 'conv', ...
                           'weights', {xavier(3,3,96,8)}, ...
                           'stride', 1, ...
                           'pad', [1 1 1 1] ,...
                           'learningRate', [1 1], ...
                           'weightDecay', [1 0]) ;
                       
net.layers{end+1} = struct('type', 'relu') ;

net.layers{end+1} = struct('type', 'pool', ...
                           'method', 'max', ...
                           'pool', [2 2], ...
                           'stride', 2, ...
                           'pad', 0) ;
                       
 
 net.layers{end+1} = struct('type', 'convt', ...
                           'weights', {xavier2(2,2,8,8)}, ...
                           'upsample', 2, ...
                           'crop', 0,...
                           'learningRate', [1 1], ...
                           'weightDecay', [1 0]);
                                             
net.layers{end+1} = struct('type', 'convt', ...
                           'weights', {xavier2(3,3,96,8)}, ...
                           'upsample', 1, ...
                           'crop', [1 1 1 1],...
                           'learningRate', [1 1], ...
                           'weightDecay', [1 0]);
 net.layers{end+1} = struct('type', 'relu') ;   
 
 net.layers{end+1} = struct('type', 'convt', ...
                           'weights', {xavier2(2,2,96,96)}, ...
                           'upsample', 2, ...
                           'crop', 0,...
                           'learningRate', [1 1], ...
                           'weightDecay', [1 0]);
                       
net.layers{end+1} = struct('type', 'convt', ...
                           'weights', {xavier2(3,3,96,96)}, ...
                           'upsample', 1, ...
                           'crop', [1 1 1 1],...
                           'learningRate', [1 1], ...
                           'weightDecay', [1 0]);
 net.layers{end+1} = struct('type', 'relu') ;   
                       
 net.layers{end+1} = struct('type', 'convt', ...
                           'weights', {xavier2(5,5,3,96)}, ...
                           'upsample', 1, ...
                           'crop', [2 2 2 2],...
                           'learningRate', [1 1], ...
                           'weightDecay', [1 0]);
 net.layers{end+1} = struct('type', 'sigmoid') ;   
                       
                  

net = vl_simplenn_tidy(net) ;
